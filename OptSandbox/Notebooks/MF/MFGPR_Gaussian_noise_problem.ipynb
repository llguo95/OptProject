{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction (**DOES NOT WORK, INTRODUCE MF-GPy FIRST**)\n",
    "\n",
    "This notebook is dedicated to outline the issues surrounding the hyperparameter optimization (HPO) of Gaussian processes in the context of Multi-fidelity Gaussian process regression (MFGPR); in particular the estimation of Gaussian noise variance based on the provided DoE.\n",
    "\n",
    "It is essential to have a properly functioning MFGPR-HPO framework if Multi-fidelity Bayesian optimization (MFBO) is to be developed.\n",
    "\n",
    "Throughout the notebook, [Taylan's GPy-MFGPR implementation](https://github.com/taylanot/GPy) (latest version if possible) shall be considered.\n",
    "\n",
    "The following packages are needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import GPy.models\n",
    "\n",
    "np.random.seed(123) # RNG control parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define some test functions that have been used in _(cite papers)_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Expensive Function\n",
    "def fe(x):\n",
    "    return (6.0 * x - 2.) ** 2 * np.sin(12 * x - 4) + 0.1\n",
    "\n",
    "# Cheap Function\n",
    "def fc(x):\n",
    "    A = 0.5\n",
    "    B = 10\n",
    "    C = 5\n",
    "    return A * fe(x) + B * (x - 0.5) - C + 0.2\n",
    "################################################################################\n",
    "\n",
    "x = np.linspace(0, 1, 100).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now introduce some control parameters that will act to show the \"undesirable\" behavior of the MFGPR-HPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_bool = True\n",
    "optimizer_string = 'lbfgsb'\n",
    "num_of_restarts = 10\n",
    "DoE_set = 1\n",
    "\n",
    "noise_var_lf = 0.5\n",
    "noise_var_hf = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data (input and output) the MFGPR experiment are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DoE_set == 1:\n",
    "    Xl = np.linspace(0, 1, 11).reshape(-1, 1)\n",
    "    Xh = np.array([0, 0.4, 0.6, 0.8, 1]).reshape(-1, 1)\n",
    "\n",
    "if DoE_set == 2:\n",
    "    Xl = np.linspace(0, 1, 6).reshape(-1, 1)\n",
    "    Xh = np.array([0, 0.4, 1]).reshape(-1, 1)\n",
    "\n",
    "X = [Xl, Xh]\n",
    "\n",
    "Yl = fc(Xl)\n",
    "Yh = fe(Xh)\n",
    "\n",
    "Y = [Yl, Yh]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the multi-fidelity Gaussian process surface modeling takes place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'GPy.models' has no attribute 'multiGPRegression'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-752e31f1aa88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiGPRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'GPy.models' has no attribute 'multiGPRegression'"
     ]
    }
   ],
   "source": [
    "m = GPy.models.multiGPRegression(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choice of HP optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.models[0].preferred_optimizer = optimizer_string\n",
    "m.models[1].preferred_optimizer = optimizer_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choice whether constraints will be applied to the HPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.models[0]['Gaussian_noise.variance'].constrain_bounded(0, 1)\n",
    "# m.models[0]['rbf.variance'].constrain_bounded(1, 20)\n",
    "# m.models[0]['rbf.lengthscale'].constrain_bounded(0.1, 5)\n",
    "\n",
    "# m.models[1]['Gaussian_noise.variance'].constrain_bounded(0, 1)\n",
    "# m.models[1]['rbf.variance'].constrain_bounded(1, 5)\n",
    "# m.models[1]['rbf.lengthscale'].constrain_bounded(0.1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choice of which HPs to fix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.models[0]['Gaussian_noise.variance'].fix(noise_var_lf)\n",
    "# m.models[0]['rbf.variance'].fix(1.5)\n",
    "# m.models[0]['rbf.lengthscale'].fix(0.1)\n",
    "\n",
    "m.models[1]['Gaussian_noise.variance'].fix(noise_var_hf)\n",
    "# m.models[1]['rbf.variance'].fix(0.1)\n",
    "# m.models[1]['rbf.lengthscale'].fix(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the HPO scheme. This will optimize the remaining, non-fixed HPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimizer_bool:\n",
    "    m.optimize_restarts(restarts=num_of_restarts, verbose=False)\n",
    "\n",
    "print(m.models[1].log_likelihood())\n",
    "\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting GPs are plotted against the true functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prediction (MAKE SURE ALL HYPERPARAMETERS ARE SET CORRECTLY)\n",
    "mu, sigma = m.predict(x)\n",
    "\n",
    "### Visualization\n",
    "vis = True\n",
    "if vis:\n",
    "    plt.plot(x, mu[0], color='b', label='MF cheap GPR (regular GPR)')\n",
    "    plt.plot(x, mu[0] + 2 * sigma[0], color='k', lw=.5)\n",
    "    plt.plot(x, mu[0] - 2 * sigma[0], color='k', lw=.5)\n",
    "    plt.fill_between(x.flatten(), mu[0].flatten() - 2 * sigma[0].flatten(), mu[0].flatten() + 2 * sigma[0].flatten(), alpha=0.2, color='b')\n",
    "\n",
    "    # plt.plot(x, mu_par, color='r', label='Regular GPR', alpha=0.3)\n",
    "    # plt.plot(x, mu_par + 2 * sigma_par, color='k')\n",
    "    # plt.plot(x, mu_par - 2 * sigma_par, color='k')\n",
    "    # plt.fill_between(x.flatten(), mu_par.flatten() - 2 * sigma_par.flatten(), mu_par.flatten() + 2 * sigma_par.flatten(), alpha=0.2)\n",
    "\n",
    "    plt.plot(x, mu[1], color='orange', label='MF expensive GPR')\n",
    "    plt.plot(x, mu[1] + 2 * sigma[1], color='k', lw=.5)\n",
    "    plt.plot(x, mu[1] - 2 * sigma[1], color='k', lw=.5)\n",
    "    plt.fill_between(x.flatten(), mu[1].flatten() - 2 * sigma[1].flatten(), mu[1].flatten() + 2 * sigma[1].flatten(), alpha=0.2, color='orange')\n",
    "\n",
    "    plt.plot(x, fc(x), '--', color='b', label='Exact cheap function')\n",
    "    plt.plot(x, fe(x), '--', color='orange', label='Exact expensive function')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.scatter(Xl, Yl, color='b')\n",
    "    plt.scatter(Xh, Yh, color='orange')\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    # plt.savefig('noise_experiment_Opt-%s_DoE%s_%s_%s.svg' % (optimizer_string, DoE_set, noise_var_lf, noise_var_hf))\n",
    "    # m.plot()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
