{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic data-driven design of Pad lamination\n",
    "\n",
    "This set of Jupyter notebooks highlights the start-to-finish procedure on how to use various Python code libraries to achieve data-driven optimization of the 2D Pad model, and is meant to supplement the first year progress report of the TU Delft - Huawei collaboration.\n",
    "\n",
    "As indicated in this document, the Bayesian machine learning paradigm has been selected as the preferred framework to perform the optimization at hand. This is because Bayesian optimization benefits from robustness in uncertainty handling and, crucially, the reduction in the number of computations needed to converge to an optimum.\n",
    "\n",
    "The document also indicates that, for its results and visualizations, a Python package called [GPyOpt](https://github.com/SheffieldML/GPyOpt) has been used. For this tutorial and the remainder of the TU Delft-Huawei collaboration, a different Python package by the name of [GPy](https://sheffieldml.github.io/GPy/) will be used to do the Gaussian process regression (GPR) for Bayesian optimization (BO). The reason for this is two-fold:\n",
    "1. The support for the GPyOpt framework has been discontinued by the original developers, which renders the risk of inability to make use of general updates.\n",
    "2. The future of this project, which is partly focused on improving upon BO, relies on multi-fidelity GPR code which has been written as an integration of the GPy software.\n",
    "\n",
    "To this end, this folder (Notebooks) contains two Jupyter notebooks:\n",
    "1. Bayesian optimization using GPy (Huawei_pt1.ipynb)\n",
    "2. Bayesian optimization using GPyOpt (deprecated) (Huawei_pt2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bayesian optimization using GPy\n",
    "\n",
    "Gaussian processes and their properties are central to the concept of Bayesian optimization (BO). In order to achieve such an optimization scheme, one has the choice to utilize a pre-existing code framework which handles Gaussian processes. [GPy](https://sheffieldml.github.io/GPy/) is such a (Python) framework, is open-source, and was developed by the Sheffield machine learning group. \n",
    "\n",
    "Let us first import GPy and a few standard packages to perform basic mathematical operations and data management. Be sure to have these installed by means of an available package manager (such as pip or conda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import GPy.models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the acquisition function that is used for the iterative selection of subsequent DoE points. In this case, the Expected Improvement acquisition function has been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acqEI(x_par, gpr, Y_train, xi=0):\n",
    "    mu_par, sigma_par = gpr.predict(np.array(x_par))\n",
    "\n",
    "    f_max_X_train = max(Y_train)\n",
    "\n",
    "    z = (mu_par - f_max_X_train - xi) / sigma_par\n",
    "    res_0 = (mu_par - f_max_X_train - xi) * norm.cdf(z) + sigma_par * norm.pdf(z)\n",
    "\n",
    "    zero_array = np.zeros(np.shape(res_0))\n",
    "    \n",
    "    res = np.multiply(res_0, np.array([np.argmax(a) for a in zip(zero_array, sigma_par)]).reshape(np.shape(res_0)))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following step, the objective function to be optimized (minimized) will be defined. The in- and output values are stored in `.txt` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gap_size(x):\n",
    "    open(\"a_Design_var1.txt\", \"w\").write(str(x[0][0]))\n",
    "    open(\"a_Design_var2.txt\", \"w\").write(str(x[0][1]))\n",
    "#     os.system(\"abaqus cae noGUI=2D-get.py\") \n",
    "#     The above line triggers the actual simulation. It is advised to uncomment this line only when the resources are available to perform the optimization procedure in full\n",
    "    return np.array(float(open(\"b_Objective_c_gap.txt\", \"r\").read().strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single initial DoE point and a design space grid is defined and for the purpose of inferencing the Gaussian processes. The inputs are scaled to fit into a standard square before the optimization procedure starts.\n",
    "\n",
    "The design parameters that are considered for this problem are `height0` with bounds `[30, 34.18]` and `rs` with bounds `[50, 200]`; please refer to Figure 1 in the accompanying document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[32., 150.]])\n",
    "Y = np.array(gap_size(X)).reshape(-1, 1)\n",
    "\n",
    "des_grid_x = np.linspace(30.0, 34.18, 100)\n",
    "des_grid_y = np.linspace(50.0, 200.0, 100)\n",
    "des_grid_xx, des_grid_yy = np.meshgrid(des_grid_x, des_grid_y)\n",
    "des_grid = np.array([des_grid_xx.reshape(-1, 1), des_grid_yy.reshape(-1, 1)]).squeeze().T\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(des_grid)\n",
    "\n",
    "X_scaled = scaler.transform(X)\n",
    "des_grid_scaled = scaler.transform(des_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can start the optimization procedure. Iteration progress data is saved in `.csv` format into a designated folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_scaled[0]\n",
    "\n",
    "n_features = 2\n",
    "k = 20 # number of iterations\n",
    "\n",
    "for i in range(k): # optimization loop\n",
    "    gpr_step = GPy.models.GPRegression(X_scaled, Y)\n",
    "    mu, sigma = gpr_step.predict(np.array(x).reshape((1, n_features)))\n",
    "\n",
    "    x = des_grid_scaled[np.argmax(acqEI(des_grid_scaled, gpr_step, Y))].reshape(-1, n_features)\n",
    "    y_step = gap_size(scaler.inverse_transform(x))\n",
    "    X_scaled = np.append(X_scaled, x).reshape(-1, n_features)\n",
    "    Y = np.append(Y, y_step).reshape(-1, 1)\n",
    "\n",
    "    np.savetxt('ProgDir_BO/in_iter_%d.csv' % (i + 1), scaler.inverse_transform(x), delimiter=\",\")\n",
    "    np.savetxt('ProgDir_BO/out_iter_%d.csv' % (i + 1), [y_step])\n",
    "    np.savetxt('ProgDir_BO/mu_iter_%d.csv' % (i + 1), gpr_step.predict(des_grid_scaled)[0].reshape(np.shape(des_grid_xx)), delimiter=\",\")\n",
    "    np.savetxt('ProgDir_BO/sigma_iter_%d.csv' % (i + 1), gpr_step.predict(des_grid_scaled)[1].reshape(np.shape(des_grid_xx)), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the optimization procedure, the inputs are scaled back to the original domain, and the optimization history is also saved in `.csv` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.inverse_transform(X_scaled)\n",
    "\n",
    "np.savetxt('ProgDir_BO/in_history.csv', X)\n",
    "np.savetxt('ProgDir_BO/out_history.csv', Y)\n",
    "np.savetxt('ProgDir_BO/in_min_pred.csv', X[np.argmin(Y)])\n",
    "np.savetxt('ProgDir_BO/out_min_pred.csv', min(Y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
